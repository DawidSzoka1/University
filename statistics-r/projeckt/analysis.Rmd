---
title: "Analiza danych dotyczących oszczędności paliwa"
subtitle: "Statystyczna analiza zbioru EPA"
author: |
  Dawid Szoka  
  89221
  
  Wydział Informatyki UwB
  
  rok akademicki 2024/2025
date: "`r Sys.Date()`"
output:
   html_document:
    toc: true
    toc_float:
      collapsed: true   
      smooth_scroll: true
    toc_depth: 4
    number_sections: true
    theme: readable      
    highlight: tango
    fig_caption: true
    code_folding: show
    df_print: paged      
fontsize: 11pt
lang: pl
---
## Potrzebne pakiety

W analizie wykorzystano następujące pakiety R:

- `tidyverse` – zestaw narzędzi do manipulacji danymi i wizualizacji  
- `e1071` – do obliczeń statystycznych (np. kurtoza, skośność)  
- `lmtest` – testowanie modeli liniowych  
- `ggplot2` – tworzenie estetycznych wykresów  
- `broom` – porządkowanie wyników modeli statystycznych  
- `DT` – interaktywne tabele
- `DescTools` – zawiera rozszerzony zestaw funkcji statystycznych do analizy opisowej
- `olsrr` – umożliwia diagnostykę i selekcję zmiennych w regresji liniowej metodami krokowymi i analitycznymi.
- `nortest` – dostarcza alternatywne testy normalności rozkładu, takie jak Cramer–von Mises czy Anderson–Darling
- `car` – oferuje zaawansowane narzędzia do analizy i diagnostyki modeli regresji i analizy wariancji.
- `gvlma` – służy do kompleksowego testowania założeń klasycznego modelu regresji liniowej.
- `ggpmisc` rozszerza ggplot2 o możliwość dodawania wzorów równań, wartości R² i statystyk bezpośrednio na wykresach.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(e1071)
library(lmtest)
library(ggplot2)
library(broom)
library(DT)
library(DescTools)
library(olsrr)
library(nortest)
library(car)
library(gvlma)
library(ggpmisc)
```

## Podstawowe Informacje o danych

### Żródło danych

Dane użyte w niniejszym projekcie pochodzą z oficjalnej, ogólnodostępnej bazy danych dostępnej na stronie:  
[https://www.fueleconomy.gov/feg/download.shtml](https://www.fueleconomy.gov/feg/download.shtml)

Serwis ten jest prowadzony przez amerykańską **Agencję Ochrony Środowiska (EPA)** oraz **Departament Energii USA**.  
Baza zawiera szczegółowe informacje dotyczące między innymi:

- zużycia paliwa,
- emisji zanieczyszczeń,
- parametrów technicznych,
- efektywności energetycznej pojazdów sprzedawanych na rynku amerykańskim.

### Przygotowanie danych

Ze względu na dużą objętość oryginalnego zbioru danych, w projekcie wykorzystano jego losową próbkę o wielkości 2000.

Dane zostały przetworzone w następujący sposób:

**set.seed(20250322)**

**vehicles <- read.csv("vehicles.csv")**

**fuel_sample <- vehicles[sample(nrow(vehicles), 2000), ]**

**write.csv(fuel_sample, "fuel_sample.csv", row.names = FALSE)**

W dalszej części analizy wykorzystujemy tylko tę próbkę (fuel_sample),
co pozwala skrócić czas obliczeń i uprościć wizualizacje, 
zachowując reprezentatywność danych.

Wczytanie danych
```{r}
set.seed(20250322)
data <- read.csv("fuel_sample.csv")
sample_data <-data %>% sample_n(150)
```
### Przykładowe dane, które będziemy analizować
```{r}
datatable(head(data, 5), filter="top",
          options = list(scrollX = TRUE, scrollY = "250px"))
```
## Parametry liczbowe i pozycyjne


### **Parametry liczbowe:**

- średnia (mean)
- wariancja (s2)
- odchylenie standardowe (s)
- odchylenie przeciętne (d)
- współczynniki zmienności Perasona (Vs, Vd)
- typowy obszar zmienności (Ts, Td)
- współczynnik asymetri (A) 
- współczynnik koncentracji (kurtosis)
- współczynnik ekscesu (K)
- współczynnik Giniego (G)
- wartość minimalna (min)
- wartość maksymalna (max)

### **Parametry pozycyjne:**
- moda (Mo)
- mediana (Me)
- kwartyle (Q1, Q3)
- decyle (D1, D9)
- rozstęp próby (R)
- odchylenie ćwiartkowe (Q)
- rozstęp międzykwartylowy (IQR)
- współczynniki zmienności (V_Q, V_Q1Q3)
- typowy obszar zmienności (T_Q)
- wskaźnik asymetrii (W_sQ)
- współczynnik asymetrii (A_Q)
- współczynnik koncentracji (W_s)


```{r warning=FALSE}
gini_coef <- function(x) {
  x <- sort(na.omit(x))
  n <- length(x)
  if (n == 0) return(NA)
  G <- sum((2 * (1:n) - n - 1) * x)
  Gini <- G / (n * sum(x))
  return(Gini)
}

opisz_liczbowa <- function(x) {
  mean_x <- mean(x, na.rm = TRUE)
  median_x <- median(x, na.rm = TRUE)
  sd_x <- sd(x, na.rm = TRUE)
  d_x <-  MeanAD(x, na.rm = TRUE)
  Q1_x <- quantile(x, 0.25, na.rm = TRUE)
  Q3_x <- quantile(x, 0.75, na.rm = TRUE)
  IQR_x <- IQR(x, na.rm = TRUE)
  Q_x <- (Q3_x - Q1_x) / (Q3_x + Q1_x)
  D1_x = quantile(x, 0.1, na.rm = TRUE)
  D9_x = quantile(x, 0.9, na.rm = TRUE)
  x_max <- max(x, na.rm = TRUE)
  x_min <- min(x, na.rm = TRUE)
  kurtosis_x <- e1071::kurtosis(x, na.rm = TRUE)
  tibble(
    mean = round(mean_x, 3),
    s2 = round(var(x, na.rm = TRUE), 3),
    s = round(sd_x, 3),
    d = round(d_x, 3),
    Vsd = round(sd_x / mean_x, 3),
    Vd = round(d_x / mean_x, 3),
    Tsd = paste0("(", round(mean_x - sd_x, 2), " - ", round(mean_x + sd_x, 2), ")"),
    Td = paste0("(", round(mean_x - d_x, 2), " - ", round(mean_x + d_x, 2), ")"),
    A = round(e1071::skewness(x, na.rm = TRUE), 3),
    kurtosis = round(kurtosis_x, 3),
    K = round(kurtosis_x - 3, 3),
    G = round(gini_coef(x), 3),
    min = round(x_min, 3),
    max = round(x_max, 3),
    Mo = round(as.numeric(names(sort(table(x), decreasing = TRUE)[1])), 3),
    Me = round(median_x, 3),
    Q1 = round(Q1_x, 3),
    Q3 = round(Q3_x, 3),
    D1 = round(D1_x, 3),
    D9 = round(D9_x, 3),
    R = round(x_max - x_min, 3),
    Q = round(Q_x, 3),
    IQR = round(IQR_x, 3),
    V_Q = round(Q_x / median_x, 3),
    V_Q1Q3 = round((Q3_x - Q1_x) / (Q3_x + Q1_x), 3),
    T_Q = paste0("(", round(median_x - Q_x, 2), " - ", round(median_x + Q_x, 2), ")"),
    W_sQ = round((Q3_x - median_x) - (median_x - Q1_x), 3),
    A_Q = round((Q3_x + Q1_x - 2 * median_x) / (2 * Q_x), 3),
    W_x = round((D9_x - D1_x) / (Q3_x - Q1_x), 3)
  )
}

statystyki <- map_df(names(data), function(nazwa) {
  x <- data[[nazwa]]
  if (is.numeric(x)) {
    opisz_liczbowa(x) %>% mutate(zmienna = nazwa)
  } 
})


statystyki <- statystyki %>% select(zmienna, everything())

```
### Wyniki
```{r}
datatable(statystyki, filter="top",
          options = list(scrollX = TRUE, scrollY = "300px"))
```
## Przedziały ufności i przetesotowanie hipotez
W tych częściach zajmiemy sie przedziałami ufności dla średniej, mediany, wariancji, frakcji
jak i hipotezami po wcześniejszym sprawdzeniu stosowanlości testów.

**Średnia i wariancja: **
Jako zmienną z rokładem normalnym przyjmiemy `youSaveSpend`, uprzednio sprawdzając hipoteze o jej rozkładzie.
Do weryfikacji tego zastosujemy `shapiro.test` z próbą o wielkości 40.

**Mediana:**
Zbadany dla zmiennej `city08` po uprzednim odrzuceniu hipotezy o rozkładznie normalnym.
Do sprawdzenia tej hipotezy zastosujemy `shapiro.test` z próbą o wielkości 80.

**Frakcja:**
Jako zmienną przyjmiemy `startStop`, sprawdzając jej stosowalność oraz jakiego restu należy do niej użyć z próbąo wielkości 100.


Wszystkie próby są losowe z ziarnem ustawionym na 20250322. Wszystkie zmienne zostaną odpowiednio przygotowane do testowania, czyli pominiecie wartości NA i losowa próbą o właściwej wielkości

### Przedziały ufności i hipotezy dla Średnia i wariancja
Sprawdzenie stosowalności
```{r}
values <- na.omit(data$youSaveSpend)
n <- 40
x <- sample(values, size = n)
sh <- shapiro.test(x)
sh

```
#### Wniosek dotyczący rozkładu normalnego

Dla zmiennej `youSaveSpend` przeprowadzono test normalności Shapiro-Wilks

- liczność próby: `r n`
- statystyka W: `r round(sh$statistic, 3)`
- wartość p: `r signif(sh$p.value, 3)`

Wartość p = `r signif(sh$p.value, 3)` jest większa niż 0.05, co oznacza, że nie ma podstaw do odrzucenia hipotezy o normalnym rozkładzie danych. Ponieważ liczność próby przekracza 30 (n = `r n`), możliwe jest stosowanie przedziału ufności dla średniej z wykorzystaniem rozkładu t-Studenta.

W związku z tym uznaje się, że przedziały ufności dla średniej i wariancji zmiennej (`youSaveSpend`) są statystycznie stosowalne.

#### Wyznacznie przedziałów ufności i przetestowanie hipotez `youSaveSpend`
```{r}
# Średnia
t_result <- t.test(x, mu = 0)
test_type <- "t-test"
ci_mean <- t_result$conf.int
p_mean <- t_result$p.value
# Wariancja
n <- length(x)
s2 <- var(x)
alpha <- 0.05
sigma0_sq <- 27500000    
chi_stat <- (n - 1) * s2 / sigma0_sq
p_value_var <- 2 * min(pchisq(chi_stat, df = n - 1), 1 - pchisq(chi_stat, df = n - 1))
ci_var <- c((n - 1) * s2 / qchisq(1 - alpha/2, df = n - 1),
            (n - 1) * s2 / qchisq(alpha/2, df = n - 1))
```
```{r setup, include=FALSE}
wniosek_mean_test <- if (p_mean < 0.05) {
  "*Test średniej:* H₀: μ = 0 vs H₁: μ ≠ 0. Ponieważ p < 0.05, odrzucamy hipotezę zerową na rzecz alternatywnej – średnia istotnie różni się od zera. Użytkownicy przeciętnie zyskują lub tracą."
} else {
  "*Test średniej:* H₀: μ = 0 vs H₁: μ ≠ 0. Ponieważ p ≥ 0.05, brak podstaw do odrzucenia hipotezy zerowej – średnia nie różni się istotnie od zera. Użytkownicy w ujęciu średnim są neutralni finansowo."
}


wniosek_mean_ci <- if (ci_mean[1] > 0) {
  sprintf("*Przedział ufności dla średniej:* [%.2f; %.2f] – użytkownicy przeciętnie osiągają zysk.", ci_mean[1], ci_mean[2])
} else if (ci_mean[2] < 0) {
  sprintf("*Przedział ufności dla średniej:* [%.2f; %.2f] – użytkownicy przeciętnie ponoszą stratę.", ci_mean[1], ci_mean[2])
} else {
  sprintf("*Przedział ufności dla średniej:* [%.2f; %.2f] zawiera 0 – nie możemy określić jednoznacznego trendu (zysk/strata).", ci_mean[1], ci_mean[2])
}


wniosek_var_test <- if (p_value_var < 0.05) {
  sprintf("*Test wariancji:* H₀: σ² = %.0f vs H₁: σ² ≠ %.0f. Ponieważ p < 0.05, odrzucamy hipotezę zerową na rzecz alternatywnej – wariancja istotnie różni się od %.0f. Zmienność w danych odbiega od przyjętej wartości.", sigma0_sq, sigma0_sq, sigma0_sq)
} else {
  sprintf("*Test wariancji:* H₀: σ² = %.0f vs H₁: σ² ≠ %.0f. Ponieważ p ≥ 0.05, brak podstaw do odrzucenia hipotezy zerowej – wariancja może być zgodna z %.0f. Rozrzut danych zgodny z oczekiwaniami.", sigma0_sq, sigma0_sq, sigma0_sq)
}

wniosek_var_ci <- if (ci_var[1] > sigma0_sq) {
  sprintf("*Przedział ufności dla wariancji:* [%.0f; %.0f] – rozrzut danych większy niż zakładano, użytkownicy mocno się różnią.", ci_var[1], ci_var[2])
} else if (ci_var[2] < sigma0_sq) {
  sprintf("*Przedział ufności dla wariancji:* [%.0f; %.0f] – użytkownicy są bardziej jednorodni niż przewidywano.", ci_var[1], ci_var[2])
} else {
  sprintf("*Przedział ufności dla wariancji:* [%.0f; %.0f] zawiera %.0f – zmienność danych może być zgodna z założeniem.", ci_var[1], ci_var[2], sigma0_sq)
}
```
#### Wyniki i wnioski
**Średnia – t-test**

*Hipotezy:*

- H₀: μ = 0 (średnia oszczędność wynosi 0)  
- H₁: μ ≠ 0 (średnia oszczędność różna od 0)  

*Wyniki:*

- Średnia: `r round(mean(x), 2)`  
- 95% CI: [`r round(ci_mean[1], 2)`, `r round(ci_mean[2], 2)`]
- p-value: `r round(p_mean, 10)`  

`r wniosek_mean_test`

`r wniosek_mean_ci` 

**Wariancja – przedział CI**

*Hipotezy:*  

- H₀: wariancja = `r  sigma0_sq`  
- H₁: wariancja ≠ `r  sigma0_sq`  

*Obliczenia dla przedziału ufności wariancji:*

- Wariancja: `r round(s2, 2)`  
- 95% CI: [`r round(ci_var[1], 2)`, `r round(ci_var[2], 2)`] 
- p-value: `r round(p_value_var, 10)`

`r wniosek_var_test`

`r wniosek_var_ci`

### Przedziały ufności dla mediany
Sprawdzenie stosowalności dla `city08`
```{r}
values_med <- na.omit(data$city08)
n_med <- 80
x_med <- sample(values_med, size = n_med)
sh_med <- shapiro.test(x_med)
```

#### Wnioski do `shapiro.test` dla `city08`

- liczność próby: `r n_med`
- statystyka W: `r round(sh_med$statistic, 3)`
- wartość p: `r signif(sh_med$p.value, 3)`

Wartość p = `r signif(sh_med$p.value, 3)` jest mniejsza niż 0.05, co oznacza, że należy odrzucić hipotezę o normalnym rozkładzie danych. Rozkład zmiennej `city08` **istotnie odbiega od normalności**, dlatego stosowanie testów parametrycznych opartych na średniej (np. test t-Studenta) **nie jest uzasadnione**.

W związku z tym:

- **Do testowania hipotezy dotyczącej mediany** należy zastosować **test Wilcoxona** dla jednej próby (`wilcox.test()`), który nie wymaga założenia normalności rozkładu.
- **Przedział ufności dla mediany**  wyznaczymy za pomocą **bootstrapowania** 

#### Wyznacznie przedziału ufności i przetesotowanie hipotezy `city08`

```{r}
mediana0 <- 20  # <- wartość pod hipotezę zerową
test_median <- wilcox.test(x_med, mu = mediana0)
p_median <- test_median$p.value

# Bootstrap CI
boot_median <- replicate(1000, median(sample(x_med, replace = TRUE)))
ci_median <- quantile(boot_median, c(0.025, 0.975))

# Wnioski
wniosek_median_test <- if (p_median < 0.05) {
  sprintf("*Test mediany:* H₀: mediana = %.2f vs H₁: mediana ≠ %.2f. Ponieważ p < 0.05, odrzucamy hipotezę zerową na rzecz alternatywnej – mediana istotnie różni się od %.2f. Użytkownicy przeciętnie osiągają wynik inny niż zakładany poziom odniesienia.", mediana0, mediana0, mediana0)
} else {
  sprintf("*Test mediany:* H₀: mediana = %.2f vs H₁: mediana ≠ %.2f. Ponieważ p ≥ 0.05, brak podstaw do odrzucenia hipotezy zerowej – mediana nie różni się istotnie od %.2f. Użytkownicy w ujęciu mediany nie odbiegają znacząco od poziomu odniesienia.", mediana0, mediana0, mediana0)
}

wniosek_median_ci <- if (ci_median[1] > mediana0) {
  sprintf("*Przedział ufności dla mediany:* [%.2f; %.2f] – użytkownicy przeciętnie osiągają wynik powyżej %.2f.", ci_median[1], ci_median[2], mediana0)
} else if (ci_median[2] < mediana0) {
  sprintf("*Przedział ufności dla mediany:* [%.2f; %.2f] – użytkownicy przeciętnie osiągają wynik poniżej %.2f.", ci_median[1], ci_median[2], mediana0)
} else {
  sprintf("*Przedział ufności dla mediany:* [%.2f; %.2f] zawiera %.2f – nie możemy jednoznacznie określić, czy użytkownicy przeciętnie osiągają wynik wyższy czy niższy.", ci_median[1], ci_median[2], mediana0)
}
```
#### Wyniki i wnioski

**Mediana - wilcox.test**

*Hipotezy:*  

- H₀: mediana = 20 
- H₁: mediana ≠ 20 

*Wyniki:*

- Mediana: `r round(median(x_med), 2)`  
- 95% CI: [`r round(ci_median[1], 2)`, `r round(ci_median[2], 2)`]  
- p-value: `r p_median`  

`r wniosek_median_test`  
`r wniosek_median_ci`

### Frakcje sprawdzenie stosowalności dla `startStop`
Sprawdzamy, czy zmiena `startStop` ma charakter binarny orazczy minimalna liczność sukcesów
i porażek przegracza ustalone warunki:

- liczba sukcesów >= 5
- liczba porażek >= 5

Na tej podstawie zdecydujemy, czy możliwe jest użycie testów, a jeśli tak, to jakich.
```{r}
x <- data$startStop
x[x == ""] <- NA
x <- na.omit(x)
unikalne <- unique(x)
is_binary <- length(unikalne) == 2
if (!is_binary) {
  wniosek_stosowalnosc <- "**Stosowalność testu frakcji:** Zmienna nie jest binarna – ma więcej lub mniej niż 2 unikalne wartości. Nie można zastosować testu frakcji."
} else {
  # Losuj próbkę
  x_sample <- sample(x, 100)
  tab <- table(x_sample)

  # Licz sukcesy i porażki
  success_label <- names(tab)[1]
  successes <- tab[[success_label]]
  failures <- sum(tab) - successes

  # Wniosek zależny od liczności
  if (min(successes, failures) >= 5) {
    test_type <- "prop.test"
    wniosek_stosowalnosc <- sprintf("**Stosowalność testu frakcji:** Zmienną można potraktować jako binarną ponieważ ilość unikatowych wartości wynosi 2. Liczba sukcesów to %d a porażek %d. Obie wartości spełniaja ustalone warunki, dzięki czemu możemy zastosować **test proporcji (%s)**.", successes, failures, test_type)
  } else {
    test_type <- "binom.test"
    wniosek_stosowalnosc <- sprintf("**Stosowalność testu frakcji:** Zmienną można potraktować jako binarną ponieważ ilość unikatowych wartości wynosi 2. Liczba sukcesów to %d a porażek %d Przynajmniej jedna liczba nie spełnia ustalonego warunku, więc zastosujemy **test dokładny (%s)**.", successes, failures, test_type)
  }
}
```

#### Wniosek stosowalności
`r wniosek_stosowalnosc`

#### Przedziały ufności i hipotezy dla frakcji zmienna `startStop`.
```{r}
hipotetyczna_frakcja <- 0.5

if(test_type == "prop.test"){
  test_result <- prop.test(successes, 100, p = hipotetyczna_frakcja, correct = FALSE)
}else{
  test_result <- binom.test(successes, 100, p = hipotetyczna_frakcja)
}
p_val <- test_result$p.value
ci <- test_result$conf.int
frac_hat <- test_result$estimate
wniosek_test <- if (p_val < alpha) {
  sprintf(paste0(
    "*Test frakcji (%s):*\n",
    "Przeprowadzono test hipotezy H₀: p = %.2f przeciwko H₁: p ≠ %.2f.\n",
    "Otrzymano wartość p = %.4f, która jest mniejsza niż poziom istotności α = %.2f.\n",
    "W związku z tym odrzucamy hipotezę zerową.\n",
    "Oznacza to, że obserwowana frakcja w próbie różni się istotnie statystycznie od %.2f – udział jednej z kategorii dominuje."
  ),
  test_type, hipotetyczna_frakcja, hipotetyczna_frakcja, p_val, alpha, hipotetyczna_frakcja)
} else {
 sprintf(paste0(
  "*Test frakcji (%s):*\n",
  "Przeprowadzono test hipotezy H₀: p = %.2f przeciwko H₁: p ≠ %.2f.\n",
  "Otrzymano wartość p = %.4f, która jest większa lub równa poziomowi istotności α = %.2f.\n",
  "W związku z tym brak podstaw do odrzucenia hipotezy zerowej.\n",
  "Nie wykazano, by udział jednej z kategorii różnił się istotnie od %.1f%%."
),
test_type, hipotetyczna_frakcja, hipotetyczna_frakcja, p_val, alpha, hipotetyczna_frakcja * 100)
}

wniosek_ci <- if (hipotetyczna_frakcja < ci[1] || hipotetyczna_frakcja > ci[2]) {
  sprintf(paste0(
    "*Przedział ufności (%.0f%%):* [%.3f; %.3f]\n",
    "Ponieważ wartość %.2f nie należy do tego przedziału,\n",
    "możemy uznać, że rzeczywista frakcja populacyjna różni się od tej wartości.\n",
    "Wynik ten potwierdza odrzucenie hipotezy zerowej – udział jednej z kategorii znacząco przeważa."
  ),
  (1 - alpha)*100, ci[1], ci[2], hipotetyczna_frakcja)
} else {
  sprintf(paste0(
    "*Przedział ufności (%.0f%%):* [%.3f; %.3f]\n",
    "Ponieważ wartość %.2f należy do tego przedziału,\n",
    "nie ma podstaw do twierdzenia, że rzeczywista frakcja populacyjna różni się od %.2f.\n",
    "Wniosek: wynik testu i przedział ufności są spójne — rzeczywista frakcja może wynosić %.2f."
  ),
  (1 - alpha)*100, ci[1], ci[2], hipotetyczna_frakcja, hipotetyczna_frakcja,hipotetyczna_frakcja)
}
```
#### Wyniki i wnioski

*Hipotezy:* 

- H₀: frakcja = 0.50  
- H₁: frakcja ≠ 0.50  

*Obliczenia dla przedziału ufności frakcji:*

- Frakcja: `r round(frac_hat, 4)`  
- 95% CI: [`r round(ci[1], 2)`, `r round(ci[2], 2)`] 
- p-value: `r round(p_val, 10)`

`r wniosek_test`

`r wniosek_ci`

## Wizualizacja danych.

W celu uzyskania poglądowej charakterystyki wybranych zmiennych, przeprowadzono wizualizację danych opartą na losowej próbce 150 obserwacji. Poniższe wykresy umożliwiają szybkie uchwycenie rozkładów zmiennych oraz zależności między nimi.

### Emisja CO2, a pojemność silnika:
```{r}
ggplot(
  sample_data %>% mutate(co2 = ifelse(co2 == 0, NA, co2)) %>% filter(!is.na(displ), !is.na(co2), !is.na(fuelType1)),
  aes(x = displ, y = co2, color = fuelType1)
) +
  geom_point(alpha = 0.6) +
  labs(
    title = "Emisja CO2 vs Pojemność silnika (próbka 100 aut)",
    x = "Pojemność silnika",
    y = "CO2 (g/mi)"
  ) +
  theme_minimal()
```

### Boxplot MPG miasto vs napęd

```{r}
ggplot(sample_data, aes(x = drive, y = city08)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "MPG w mieście a napęd", x = "Napęd", y = "MPG miasto") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


#### Wnioski

- **Najwyższa mediana MPG:**

  - 2-Wheel Drive ma najwyższą medianę (ok. 23 MPG), co oznacza, że pojazdy z tym napędem są najbardziej paliwooszczędne w mieście.

  - Front-Wheel Drive i Part-time 4-Wheel Drive również wykazują relatywnie wysokie mediany.

- **Najniższa mediana MPG:**

  - 4-Wheel Drive oraz Rear-Wheel Drive osiągają najniższe mediany MPG (ok. 13–17 MPG), co wskazuje na najmniejszą efektywność paliwową w warunkach miejskich.

- **Rozrzut danych i wartości odstające:**

  - Front-Wheel Drive i Part-time 4-Wheel Drive mają najszerszy rozrzut wartości oraz najwięcej wartości odstających (outliers), co może sugerować dużą różnorodność modeli i silników.

  - All-Wheel Drive i 4-Wheel or All-Wheel Drive mają dość zwarte rozkłady, ale z niskimi wartościami MPG.

- **Efektywność napędów:**

  - Napędy przednie i częściowo 4WD generalnie zapewniają lepszą efektywność w mieście niż klasyczne pełne 4WD czy napędy tylne, co jest zgodne z oczekiwaniami (mniejsze opory i masa układów napędowych).

#### Podsumowanie:

- Pojazdy z napędem na przednie koła (Front-Wheel Drive) lub na dwa koła (2-Wheel Drive) są najbardziej ekonomiczne w warunkach miejskich.

- Pełne napędy 4x4 (4-Wheel Drive, AWD) i napędy tylne zużywają więcej paliwa w mieście.

- Obecność wartości odstających może świadczyć o różnorodności modeli i technologii w danej kategorii napędu.

- Dla kierowców poruszających się głównie w warunkach miejskich, napęd FWD lub 2WD będzie optymalny pod względem oszczędności paliwa.


### Średnia emisja CO2 w czasie
```{r}
sample_data %>% filter(year >= 2012.5) %>%
  group_by(year) %>%
  summarise(średnie_CO2 = mean(co2, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = średnie_CO2)) +
  geom_line(color = "darkred", linewidth = 1.2) +
  geom_point(color = "red") +
  labs(title = "Emisja CO2 w czasie", x = "Rok", y = "CO2 (g/mi)") +
  theme_minimal()
```

#### Wnioski z danych:

- **Lata 2013–2014:**

  - Emisja CO₂ utrzymywała się na stosunkowo stabilnym poziomie – około 360 g/mi.

- **Lata 2015–2018:**

  - Wzrost emisji do około 470 g/mi w 2018 – zauważalny trend wzrostowy, możliwie związany z większą liczbą pojazdów o wyższym zużyciu paliwa (np. SUV-y, silniki wysokiej mocy).

- **Lata 2019–2021:**

  - Stopniowy spadek emisji, z wyraźnym minimum w 2021 r. (~270 g/mi). Może być efektem:

  - wzrostu popularności pojazdów hybrydowych/elektrycznych,
spadku aktywności transportowej w okresie pandemii COVID-19.

- **Lata 2022–2024:**

  - Nagły wzrost emisji, osiągając maksimum (~580 g/mi) w 2024. Wzrost może być spowodowany:

    - wzrostem sprzedaży pojazdów o wyższym spalaniu,

    - ożywieniem gospodarczym i zwiększoną mobilnością po pandemii.

- **Rok 2025:**

  - Ponowny spadek emisji do ok. 420 g/mi – możliwy efekt regulacji emisji, wdrażania technologii niskoemisyjnych lub zmian rynkowych.




#### Podsumowanie
- **Emisja CO₂ z pojazdów zmieniała się dynamicznie w ostatnich latach, co może być związane z:**

  - zmianami w preferencjach konsumenckich (np. wzrost SUV-ów vs auta elektryczne),

  - wpływem polityk klimatycznych,

  - globalnymi wydarzeniami (np. pandemia COVID-19).

- **Najniższy poziom emisji (2021) i najwyższy (2024) pokazują silną zmienność rynku transportowego.**

- **Potencjalnie pozytywny trend na rok 2025 – spadek emisji – warto obserwować w kolejnych latach.**

### Heatmapa MPG autostrada vs cylindry i paliwo
```{r}
sample_data  %>%
  group_by(cylinders, fuelType1) %>%
  summarise(śr_mpg_autostrada = mean(highway08, na.rm = TRUE), .groups = "drop") %>%
  ggplot(aes(x = factor(cylinders), y = fuelType1, fill = śr_mpg_autostrada)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "MPG autostrada wg cylindrów i paliwa", x = "Cylindry", y = "Rodzaj paliwa") +
  theme_minimal()
```

#### Wnioski statystyczne:

- **Najwyższa efektywność paliwowa:**
Samochody na Regular Gasoline z 3 cylindrami osiągają najwyższe wartości MPG na autostradzie (ponad 40 MPG – najciemniejszy niebieski kolor).

- **Spadek wydajności wraz z liczbą cylindrów:**
Niezależnie od rodzaju paliwa, wzrost liczby cylindrów powoduje spadek efektywności paliwowej. Dla 8 i 12 cylindrów średnie MPG spada poniżej 25 MPG (jasnofioletowy kolor).

- **Paliwa wysokooktanowe i diesel:**

  - Diesel oraz Premium Gasoline przy 4 cylindrach osiągają stosunkowo dobre wyniki, ale gorsze niż Regular Gasoline przy tej samej liczbie cylindrów.
  
  - Diesel przy 4 cylindrach ma nieco niższe MPG niż Regular Gasoline, ale lepsze niż przy wyższych liczbach cylindrów.

- **Niedostępność danych (brak koloru):**
Braki kolorów przy niektórych kombinacjach (np. Diesel z 6, 8 lub 12 cylindrami) sugerują, że dla tych kategorii brak jest danych lub nie były reprezentowane w zestawie.

#### Podsumowanie:

- Małe silniki (3–4 cylindry) zasilane Regular Gasoline są najbardziej efektywne paliwowo na autostradzie.

- Wraz ze wzrostem liczby cylindrów spada efektywność paliwowa niezależnie od rodzaju paliwa.

- Regular Gasoline zapewnia najlepszy kompromis między wydajnością a liczbą cylindrów.

## Analiza regresji liniowej.
Celem tej części projektu była analiza zależności pomiędzy pojemnością silnika (displ) a efektywnością paliwową w cyklu miejskim (city08). Zmienna city08 reprezentuje liczbę mil, jakie pojazd jest w stanie przejechać w warunkach miejskich na jednym galonie paliwa (MPG – miles per gallon). Oznacza to, że im wyższa jej wartość, tym mniejsze rzeczywiste zużycie paliwa. Obie zmienne mają charakter ilościowy, co uzasadnia zastosowanie modelu regresji liniowej.

### Przygotowanie modelu
```{r}
data_clean <- data %>% filter(!is.na(city08), !is.na(displ))

## Dopasowanie modelu regresji liniowej
model <- lm(city08 ~  displ, data = data_clean)

## Podsumowanie modelu
summary(model)
```

### Interpretacja modelu:

- Otrzymany model regresji liniowej opisuje zależność między efektywnością paliwową w mieście (city08) a pojemnością silnika (displ) i ma postać: 
`city08 = 27.71 - 2.86 x displ`

- **Współczynnik kierunkowy = -2.86**, co oznacza, że każdorazowy wzrost pojemności silnika o 1 litr powoduje spadek efektywności paliwowej w mieście o 2.86 MPG – czyli pojazd przejedzie o 2.86 mil mniej na jednym galonie paliwa.
- **Wartość R² = 0.4872**, co oznacza, że model wyjaśnia ok. 49% zmienności zmiennej city08. To sugeruje, że pojemność silnika ma znaczący wpływ na efektywność paliwową, jednak warto byłoby rozważyć uwzględnienie dodatkowych predyktorów.
- Model jest istotny statystycznie (p-value < 2.2e-16).


### Diagnostyka reszt

Test normalności reszt
```{r}
shapiro.test(model$residuals)
harvtest(model)
dwtest(model)
gvlma(model)
```
### Wnioski diagnostyczne:

- Shapiro-Wilk (p < 2.2e-16): reszty nie są normalne – silna asymetria i problemy w ogonach.
- Harvey-Collier (p = 0.8847): brak dowodów na nieliniowość.
- GVLMA:
  - Naruszone są założenia: symetria (skewness), kurtoza, liniowość (link).
  - Heteroskedastyczność nie występuje (p = 0.3288).
- Durbin-Watson (p = 0.9519): brak autokorelacji.

Podsumowanie:

- Istnieje silna, ujemna zależność pomiędzy pojemnością silnika a efektywnością paliwową w mieście.
- Model jest statystycznie istotny, ale narusza założenie normalności reszt oraz wykazuje problemy z rozkładem (asymetria i kurtoza).
- Jednak testy Harvey-Colliera i Durbin-Watsona potwierdzają poprawność założenia liniowości i brak autokorelacji, a brak heteroskedastyczności również wspiera trafność modelu.
- W interpretacji wyników (szczególnie p-value) należy zachować ostrożność.
- Mimo ograniczeń, model dobrze ilustruje ogólną zależność i może być użyteczny w analizie porównawczej.

### Graficzna diagnostyka modelu

```{r warning=FALSE}
ggplot(data_clean, aes(x = displ, y = city08)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(title = "Zależność zużycia paliwa w mieście od pojemności silnika",
       x = "Pojemność silnika (litry)",
       y = "Efektywność paliwowa w mieście (MPG)") +
  theme_minimal()
```
```{r}
data_clean |>  ggplot(aes(x= displ, y= city08))+
 geom_point()+
 geom_smooth(method= lm,color= 'red') +
 theme_bw()+
 labs(x = 'Pojemność silnika (litry)',
 y = 'Efektywność paliwowa w mieście (MPG)') +
 stat_ma_eq(mapping= use_label(c("R2", "eq")),color= 'red') +
 stat_fit_tb(label.y= 0.9, label.x= .9)
```

Dane pokazują wyraźną ujemną zależność: większe silniki są mniej oszczędne w warunkach miejskich.

Linia regresji dobrze odwzorowuje ogólny trend, choć obserwujemy rozproszenie danych szczególnie przy niższych wartościach pojemności – może to sugerować, że inny typ modelu (np. nieliniowy) mógłby lepiej dopasować się do danych.

Model liniowy jest prosty i dobrze nadaje się do celów porównawczych, ale – jak pokazały testy diagnostyczne – narusza założenia (nienormalność reszt, nieliniowość), dlatego jego interpretacja wymaga ostrożności.

```{r}
par(mfrow = c(2,2))
plot(model)
```

### Interpretacja wykresów (plot)

- **Residuals vs Fitted:** rozrzut reszt nie jest losowy – szczególnie dla wyższych wartości dopasowanych pojawia się wachlarzowaty kształt, co może świadczyć o nieliniowości lub zmiennej wariancji.
- **Q-Q plot:** reszty nie mają rozkładu normalnego – odchylenia w ogonach są silne i potwierdzają wyniki testu Shapiro-Wilka.
- **Scale-Location plot:** rosnąca wariancja reszt wraz z wartościami dopasowanymi może wskazywać na heteroskedastyczność, choć testy formalne jej nie wykazały.
- **Residuals vs Leverage:** kilka punktów może mieć silny wpływ na model. Są to obserwacje z dużymi resztami i wysokim leverage – warto rozważyć ich dalszą analizę lub ewentualne wykluczenie.


### Podsumowanie regresji

Model liniowy dobrze odwzorowuje ogólny trend: większa pojemność silnika wiąże się z mniejszą efektywnością paliwową. Pomimo naruszeń niektórych założeń klasycznej regresji (szczególnie normalności reszt), model pozostaje użyteczny do analizy zależności i celów porównawczych. W interpretacji wyników statystycznych, zwłaszcza p-value, należy jednak zachować ostrożność.

Dla zwiększenia dokładności analizy w przyszłości można rozważyć:

- zastosowanie transformacji zmiennych (np. logarytmicznej),

- użycie regresji odpornej na naruszenia założeń,

- uwzględnienie dodatkowych zmiennych objaśniających (np. ilość cylindrów, typ napędu, rodzaj paliwa).

## Podsumowanie
- Przeprowadzono pełną analizę statystyczną wybranej próbki danych dotyczących pojazdów.
- Obliczono parametry liczbowe i pozycyjne dla wszystkich zmiennych.
- Dla zmiennej `youSavedSpend` wykonano:
  - przedziały ufności (średnia, wariancja),
  - testy istotności (dla średnich, wariancji ),
  - przetestowano hipoteze (średnia, wariancja),
- Dla zmiennej `city08` wykonano:
  - przedział ufności (mediany),
  - testy istotności (mediany)
  - przetestowano hipoteze (mediany)
- Dla zmiennej `startStop` wykonano:
  - przedzał ufności (frakcji),
  - testy istotności (frakcji),
  - przetestowano hipoteze (frakcji)
  
- Analiza regresji pomiędzy zmienna `displ` a `city08`
- Stosowalność testów była każdorazowo weryfikowana.
- Przedstawiono co najmniej 4 wykresy ilustrujące zależności w danych.
- Wszystkie wyniki zostały zinterpretowane w kontekście statystycznym.

**Dziękuję za uwagę!**