---
title: "Analiza danych"
author: "Dawid Szoka"
date: "2025-04-17"
output:
   ioslides_presentation:
    widescreen: true
    smaller: true
---
## Wczytywanie danych i biblioteki
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(e1071)
library(lmtest)
library(ggplot2)
library(broom)
library(DT)
set.seed(20250322)
data <- read.csv("fuel_sample.csv")
sample_data <-data %>% sample_n(100)
```
---

```{r echo=FALSE}
datatable(head(data, 5), filter="top",
          options = list(scrollX = TRUE, scrollY = "250px"),
          caption = "Przykladowe dane")
```
## Parametry liczbowe i pozycyjne
```{r}
opisz_liczbowa <- function(x) {
  tibble(
    typ = "numeryczna",
    mean = mean(x, na.rm = TRUE),
    sd = sd(x, na.rm = TRUE),
    min = min(x, na.rm = TRUE),
    Q1 = quantile(x, 0.25, na.rm = TRUE),
    median = median(x, na.rm = TRUE),
    Q3 = quantile(x, 0.75, na.rm = TRUE),
    max = max(x, na.rm = TRUE),
    IQR = IQR(x, na.rm = TRUE),
    skewness = skewness(x, na.rm = TRUE),
    kurtosis = kurtosis(x, na.rm = TRUE),
    moda = NA,
    n_unique = length(unique(x))
  )
}

```
## Funkcja opisująca zmienne nieliczbowe
```{r}
opisz_nieliczbowa <- function(x) {
  tab <- sort(table(x), decreasing = TRUE)
  najczestsza <- names(tab)[1]
  najrzadsza <- names(tab)[length(tab)]
  tibble(
    typ = "kategoryczna",
    mean = NA,
    sd = NA,
    min = NA,
    Q1 = NA,
    median = NA,
    Q3 = NA,
    max = NA,
    IQR = NA,
    skewness = NA,
    kurtosis = NA,
    moda = najczestsza,
    freq_moda = tab[1],
    prop_moda = round(tab[1] / sum(tab), 3),
    n_unique = length(unique(x)),
    najrzadsza = najrzadsza,
    n_NA = sum(is.na(x))
  )
}
```
## Przejście po wszystkich kolumnach
```{r}
statystyki <- map_df(names(data), function(nazwa) {
  x <- data[[nazwa]]
  if (is.numeric(x)) {
    opisz_liczbowa(x) %>% mutate(zmienna = nazwa)
  } else {
    opisz_nieliczbowa(x) %>% mutate(zmienna = nazwa)
  }
})

# Przenosimy kolumnę "zmienna" na początek
statystyki <- statystyki %>% select(zmienna, typ, everything())

```
## 
```{r echo=FALSE}
datatable(statystyki, filter="top",
          options = list(scrollX = TRUE, scrollY = "300px"),
          caption = "Podsumowanie wszystkich zmiennych")
```
## Przedziały ufności
Sprawdzenie stosowalności
```{r}
values <- na.omit(data$youSaveSpend)
n <- 40
x <- sample(values, size = n)
sh <- shapiro.test(x)
sh
```
## Wnisoek dotyczacy stosowalności przedziałów ufności

Dla zmiennej `youSaveSpend` przeprowadzono test normalności Shapiro-Wilks

- liczność próby: `r n`
- statystyka W: `r round(sh$statistic, 3)`
- wartość p: `r signif(sh$p.value, 3)`

Wartość p = `r signif(sh$p.value, 3)` jest większa niż 0.05, co oznacza, że nie ma podstaw do odrzucenia hipotezy o normalnym rozkładzie danych. Ponieważ liczność próby przekracza 30 (n = `r n`), możliwe jest stosowanie przedziału ufności dla średniej z wykorzystaniem rozkładu t-Studenta.

W związku z tym uznaje się, że przedziały ufności dla (`youSaveSpend`) są statystycznie stosowalne.

## Wyznacznie przedziałów ufności `youSaveSpend`
```{r}
# Średnia
t_result <- t.test(x)
ci_mean <- t_result$conf.int
p_mean <- t_result$p.value
# Mediana
y <- x + runif(length(x), min = -1e-5, max = 1e-5)
wilcox_result <- wilcox.test(y, mu = 0)
p_median <- wilcox_result$p.value
boot_median <- replicate(1000, median(sample(x, replace = TRUE)))
ci_median <- quantile(boot_median, c(0.025, 0.975))
# Wariancja
n <- length(x)
s2 <- var(x)
alpha <- 0.05
ci_var <- c((n - 1) * s2 / qchisq(1 - alpha/2, df = n - 1),
            (n - 1) * s2 / qchisq(alpha/2, df = n - 1))
# Frakcja dodatnich
frakcja <- sum(x > 0)
prop_result <- prop.test(frakcja, n, p = 0.5)
ci_frac <- prop_result$conf.int
p_frac <- prop_result$p.value

```
```{r setup, include=FALSE}
wniosek_mean <- if (p_mean < 0.05) {
  "**Wniosek:** Ponieważ p < 0.05, odrzucamy hipotezę zerową (H₀: μ = 0) na rzecz alternatywnej (H₁: μ ≠ 0). Oznacza to, że średnia oszczędność użytkowników istotnie różni się od zera. Użytkownicy przeciętnie albo istotnie zyskują, albo tracą."
} else {
  "**Wniosek:** Ponieważ p ≥ 0.05, brak podstaw do odrzucenia hipotezy zerowej (H₀: μ = 0). Średnia oszczędność użytkowników nie różni się istotnie od zera – przeciętny wpływ finansowy jest neutralny."
}
wniosek_median <- if (p_median < 0.05) {
  "**Wniosek:** Ponieważ p < 0.05, odrzucamy hipotezę zerową (H₀: mediana = 0) na rzecz alternatywnej (H₁: mediana ≠ 0). Mediana oszczędności istotnie różni się od zera – połowa użytkowników osiąga realny zysk lub stratę."
} else {
  "**Wniosek:** Ponieważ p ≥ 0.05, brak podstaw do odrzucenia hipotezy zerowej. Mediana nie różni się istotnie od zera – typowy użytkownik nie zyskuje ani nie traci w sposób istotny statystycznie."
}
wniosek_var <- if (s2 > 1e5) {
  "**Wniosek:** Wysoka wariancja sugeruje dużą rozpiętość wyników – użytkownicy znacznie się różnią pod względem wartości oszczędności/straty. Dla dalszych analiz warto rozważyć podział na grupy."
} else {
  "**Wniosek:** Niska lub umiarkowana wariancja – użytkownicy są relatywnie podobni pod względem finansowym. Zmienność danych jest ograniczona."
}
wniosek_frac <- if (p_frac < 0.05) {
  "**Wniosek:** Ponieważ p < 0.05, odrzucamy hipotezę zerową (H₀: p = 0.5) na rzecz alternatywnej (H₁: p ≠ 0.5). Istnieje istotna różnica w proporcji osób, które zyskują względem tracących. Większość (lub mniejszość) korzysta na tym modelu."
} else {
  "**Wniosek:** Ponieważ p ≥ 0.05, brak podstaw do odrzucenia hipotezy zerowej. Proporcja osób zyskujących i tracących jest zbliżona – model nie faworyzuje żadnej grupy."
}
```

## Średnia – t-test

**Hipotezy:**  
- H₀: μ = 0 (średnia oszczędność wynosi 0)  
- H₁: μ ≠ 0 (średnia oszczędność różna od 0)  

**Wyniki:**  
- Średnia: `r round(mean(x), 2)`  
- 95% CI: [`r round(ci_mean[1], 2)`, `r round(ci_mean[2], 2)`]
- p-value: `r round(p_mean, 10)`  

`r wniosek_mean`


## Mediana – test Wilcoxona

**Hipotezy:**  
- H₀: mediana = 0  
- H₁: mediana ≠ 0  

**Wyniki:**  
- Mediana: `r round(median(x), 2)`
- 95% CI:  [`r round(ci_median[1], 2)` , `r round(ci_median[2], 2)`]
- p-value: `r round(p_median, 10)`  

`r wniosek_median`



## Wariancja – przedział CI

**Obliczenia dla przedziału ufności wariancji:**  
- Wariancja: `r round(s2, 2)`  
- 95% CI: [`r round(ci_var[1], 2)`, `r round(ci_var[2], 2)`] 

`r wniosek_var`



## Frakcja wartości dodatnich – prop.test

**Hipotezy:**  
- H₀: p = 0.5 (proporcja dodatnich wartości = 50%)  
- H₁: p ≠ 0.5  

**Wyniki:**  
- Frakcja: `r frakcja` z `r n` (czyli `r round(frakcja/n, 2)` procent dodatnich)  
- 95% CI: [`r round(ci_frac[1], 2)`, `r round(ci_frac[2], 2)`] 
- p-value: `r round(p_frac, 10)`  

`r wniosek_frac`

## Emisja CO2 a pojemność silnika:
```{r echo=FALSE}
ggplot(
  sample_data %>% mutate(co2 = ifelse(co2 == 0, NA, co2)) %>% filter(!is.na(displ), !is.na(co2), !is.na(fuelType1)),
  aes(x = displ, y = co2, color = fuelType1)
) +
  geom_point(alpha = 0.6) +
  labs(
    title = "Emisja CO2 vs Pojemność silnika (próbka 100 aut)",
    x = "Pojemność silnika",
    y = "CO2 (g/mi)"
  ) +
  theme_minimal()
```

## Boxplot MPG miasto vs napęd

```{r echo=FALSE}
ggplot(sample_data, aes(x = drive, y = city08)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "MPG w mieście a napęd", x = "Napęd", y = "MPG miasto") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Średnia emisja CO2 w czasie
```{r echo=FALSE}
sample_data %>% filter(year >= 2012.5) %>%
  group_by(year) %>%
  summarise(średnie_CO2 = mean(co2, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = średnie_CO2)) +
  geom_line(color = "darkred", linewidth = 1.2) +
  geom_point(color = "red") +
  labs(title = "Emisja CO2 w czasie", x = "Rok", y = "CO2 (g/mi)") +
  theme_minimal()
```

## Heatmapa MPG autostrada vs cylindry i paliwo
```{r echo=FALSE}
sample_data  %>%
  group_by(cylinders, fuelType1) %>%
  summarise(śr_mpg_autostrada = mean(highway08, na.rm = TRUE), .groups = "drop") %>%
  ggplot(aes(x = factor(cylinders), y = fuelType1, fill = śr_mpg_autostrada)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "MPG autostrada wg cylindrów i paliwa", x = "Cylindry", y = "Rodzaj paliwa") +
  theme_minimal()
```

## Analiza regresji
```{r echo=FALSE}
data_clean <- data %>% filter(!is.na(city08), !is.na(displ))

## Dopasowanie modelu regresji liniowej
model <- lm(city08 ~ displ, data = data_clean)

## Podsumowanie modelu
summary(model)
```

## Interpretacja modelu:

- **Model regresji liniowej:** `city08 ~ displ`
- Współczynnik kierunkowy = -2.82 → wraz ze wzrostem pojemności silnika o 1 litr, średnie spalanie w mieście spada o ok. 2.82 mpg.
- **Wartość R² = 0.51**, co oznacza, że model wyjaśnia 51% zmienności zużycia paliwa.
- Oba współczynniki istotne statystycznie (**p < 0.05**).


## Diagnostyka reszt

```{r echo=FALSE}
shapiro.test(residuals(model))
bptest(model)
```
### Wnioski diagnostyczne:

- **Test Shapiro-Wilka**: p < 0.05 → reszty nie są rozkładem normalnym.
- **Test Breuscha-Pagana**: p < 0.05 → występuje heteroskedastyczność.
- Założenia klasycznego modelu regresji są naruszone. Możliwe konsekwencje:
  - zaniżone błędy standardowe,
  - zawyżone testy t,
  - niepewna interpretacja p-value.

---

```{r echo=FALSE, warning=FALSE}
ggplot(data_clean, aes(x = displ, y = city08)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  labs(title = "Zależność zużycia paliwa w mieście od pojemności silnika",
       x = "Pojemność silnika (litry)",
       y = "Zużycie paliwa w mieście (MPG)") +
  theme_minimal()
```



## Graficzna diagnostyka modelu

```{r echo=FALSE}
par(mfrow = c(1,2))
plot(model, which = 1, main = "Reszty vs dopasowane")
plot(model, which = 2, main = "Q-Q plot reszt")
```

- Rozrzut reszt wskazuje na **heteroskedastyczność**.
- Q-Q plot wskazuje na odchylenia od normalności (szczególnie w ogonach).



## Podsumowanie

- **Istotny negatywny związek** między `displ` a `city08`.
- Model istotny statystycznie (**p < 2.2e-16**).
- **Zastrzeżenia co do jakości modelu**:
  - Brak normalności reszt.
  - Zmienna wariancja reszt (heteroskedastyczność).

Zalecenia:

- Rozważyć transformację zmiennych (np. logarytmiczną).
- Rozważyć użycie regresji odpornych na heteroskedastyczność.
- Interpretować wartości p z ostrożnością.

## Dziękuje za uwage

Dawid Szoka
